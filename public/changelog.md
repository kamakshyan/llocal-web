## 1.0.0-beta.5 ( Major Release )
> 20th June, 2024
### Official Mac Support
- Mac support is here. This has been one of the major goals for the project.
- Ollama, can be downloaded and prompted to be installed if detected as not installed.

### What's Changed
* refactor: improve error handling in checkOllama function by @virajbhartiya in https://github.com/kartikm7/llocal/pull/1
* fix : partial mac setup by @dandonarahul2002 in https://github.com/kartikm7/llocal/pull/2

### New Contributors
* @virajbhartiya made their first contribution in https://github.com/kartikm7/llocal/pull/1
* @dandonarahul2002 made their first contribution in https://github.com/kartikm7/llocal/pull/2

**Full Changelog**: https://github.com/kartikm7/llocal/compare/v1.0.0-beta.2...v1.0.0-beta.4

## 1.0.0-beta.3
> 27th June, 2024
### Note
- This version was not documented (I was still figuring it out)

## 1.0.0-beta.2
> Pre-release
### Functional Features
- Auto-updater

## 1.0.0-beta.1
> Pre-release
### Functional Features
- Ollama auto-downloader
- Ollama auto-installer

### User experience features
- New logo (I think it might just count as a feature)

## 1.0.0-beta
> Pre-release
### Functional Features
- Ollama support (both, pulling models and chatting)
- Local data storage (no cloud connectivity)
- Chat streaming 
- Support to switch between models

### UX Features:
- Theming options ( across 5 themes)
- Dark mode and light mode support

> Note: It is still in a pre-release phase, so all features might not work as intended.